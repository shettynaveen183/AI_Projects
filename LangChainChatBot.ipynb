{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-openai) (0.3.19)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-openai) (1.54.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.67.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"your_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3490: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-4',             \n",
    "                  model_kwargs={'seed': 365},\n",
    "                  temperature=0,\n",
    "                  max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke('''I've recently adopted a dog.Could you sugest me some dog names?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, here are some suggestions:\\n\\nMale Dog Names:\\n1. Max\\n2. Charlie\\n3. Cooper\\n4. Buddy\\n5. Jack\\n6. Rocky\\n7. Duke\\n8. Bear\\n9. Zeus\\n10. Toby\\n\\nFemale Dog Names:\\n1. Bella\\n2. Lucy\\n3. Daisy\\n4. Luna\\n5. Lola\\n6. Sadie\\n7. Molly\\n8. Bailey\\n9. Stella\\n10. Maggie\\n\\nUnisex Dog Names', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 23, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run-9db16408-43b8-4efd-8504-6f28b3be3a59-0', usage_metadata={'input_tokens': 23, 'output_tokens': 100, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some suggestions:\n",
      "\n",
      "Male Dog Names:\n",
      "1. Max\n",
      "2. Charlie\n",
      "3. Cooper\n",
      "4. Buddy\n",
      "5. Jack\n",
      "6. Rocky\n",
      "7. Duke\n",
      "8. Bear\n",
      "9. Zeus\n",
      "10. Toby\n",
      "\n",
      "Female Dog Names:\n",
      "1. Bella\n",
      "2. Lucy\n",
      "3. Daisy\n",
      "4. Luna\n",
      "5. Lola\n",
      "6. Sadie\n",
      "7. Molly\n",
      "8. Bailey\n",
      "9. Stella\n",
      "10. Maggie\n",
      "\n",
      "Unisex Dog Names\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System and Humar Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    model_kwargs={'seed':365}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content=\"I've recenty adapted a  dog can you suggest some dog names?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some suggestions:\n",
      "\n",
      "Male Dog Names:\n",
      "1. Max\n",
      "2. Charlie\n",
      "3. Cooper\n",
      "4. Buddy\n",
      "5. Jack\n",
      "6. Rocky\n",
      "7. Duke\n",
      "8. Bear\n",
      "9. Zeus\n",
      "10. Toby\n",
      "\n",
      "Female Dog Names:\n",
      "1. Bella\n",
      "2. Lucy\n",
      "3. Daisy\n",
      "4. Luna\n",
      "5. Lola\n",
      "6. Sadie\n",
      "7. Molly\n",
      "8. Bailey\n",
      "9. Stella\n",
      "10. Zoe\n",
      "\n",
      "Unisex Dog Names:\n",
      "1. Harley\n",
      "2. Riley\n",
      "3. Casey\n",
      "4. Bailey\n",
      "5. Sam\n",
      "6. Alex\n",
      "7. Charlie\n",
      "8. Dakota\n",
      "9. Jamie\n",
      "10. Taylor\n",
      "\n",
      "Unique Dog Names:\n",
      "1. Orion\n",
      "2. Juno\n",
      "3. Atlas\n",
      "4. Echo\n",
      "5. Zephyr\n",
      "6. Indigo\n",
      "7. Quasar\n",
      "8. Lyric\n",
      "9. Nimbus\n",
      "10. Vega\n",
      "\n",
      "I hope you find the perfect name for your new furry friend!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s = SystemMessage(content='You are Marv, a chatbot that reluctantly answers questions with sarcastic responses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_s,message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new family member. How about \"Bark Twain\" or \"Sir Waggington\"? Maybe \"Biscuit Overlord\" or \"Furry McFurFace\"? Or, if you're feeling particularly uninspired, \"Dog\".\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt templates and prompt values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "System:\n",
    "{description}\n",
    "\n",
    "\n",
    "Human:\n",
    "I've recently adopted a {pet}.\n",
    "Could you suggest some {pet} names?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['description', 'pet'] input_types={} partial_variables={} template=\"\\nSystem:\\n{description}\\n\\n\\nHuman:\\nI've recently adopted a {pet}.\\nCould you suggest some {pet} names?\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Pet type: dog\n",
      "Description: The chatbot should reluctantly answer questions with sarcastic responses.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"description\", \"pet\"],\n",
    "    template=\"\"\"The chatbot should reluctantly answer questions with sarcastic responses.\n",
    "Pet type: {pet}\n",
    "Description: {description}\"\"\"\n",
    ")\n",
    "\n",
    "# Format the prompt using the template\n",
    "prompt_value = prompt_template.format(\n",
    "    description=\"The chatbot should reluctantly answer questions with sarcastic responses.\",\n",
    "    pet=\"dog\"\n",
    ")\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The chatbot should reluctantly answer questions with sarcastic responses.\\nPet type: dog\\nDescription: The chatbot should reluctantly answer questions with sarcastic responses.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts.chat import (\n",
    "    SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model='gpt-4',\n",
    "    model_kwargs={'seed':365},\n",
    "    temperature=0,\n",
    "    max_tokens=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = '''I've recently adopted a {pet}. Could you suggest some {pet} names'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_s = SystemMessagePromptTemplate.from_template(template=TEMPLATE_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_h = HumanMessagePromptTemplate.from_template(template=TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages([message_template_s,message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. Could you suggest some {pet} names\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['description', 'pet'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. Could you suggest some {pet} names\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAT MESSAGE HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain.chains.llm (from versions: none)\n",
      "ERROR: No matching distribution found for langchain.chains.llm\n"
     ]
    }
   ],
   "source": [
    "pip install langchain.chains.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.36-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.4-cp39-cp39-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (0.3.19)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (0.1.143)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.0-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.17.2-cp39-cp39-win_amd64.whl.metadata (68 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Using cached langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "Downloading aiohttp-3.11.4-cp39-cp39-win_amd64.whl (440 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp39-cp39-win_amd64.whl (298 kB)\n",
      "Using cached multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.0-cp39-cp39-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.17.2-cp39-cp39-win_amd64.whl (90 kB)\n",
      "Installing collected packages: propcache, numpy, multidict, greenlet, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, SQLAlchemy, aiosignal, aiohttp, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.4 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 frozenlist-1.5.0 greenlet-3.1.1 langchain-0.3.7 langchain-text-splitters-0.3.2 multidict-6.1.0 numpy-1.26.4 propcache-0.2.0 yarl-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain_community)\n",
      "  Downloading SQLAlchemy-2.0.35-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (3.11.4)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 10.6 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.3 MB/s eta 0:00:00\n",
      "Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: SQLAlchemy, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import(\n",
    "    SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate,ChatPromptTemplate\n",
    ")\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3490: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4',\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    model_kwargs={'seed':365}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_info = ChatMessageHistory()\n",
    "background_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_info.add_user_message(\"Can you give me an interesting fact I probably didn't know about?\")\n",
    "background_info.add_ai_message(\"Sure, did you know its 85\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Can you give me an interesting fact I probably didn't know about?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, did you know its 85', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Can you give me an interesting fact I probably didn't know about?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sure, did you know its 85', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_info.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InMemoryChatMessageHistory' object has no attribute 'model_dump_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m background_info\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mbackground_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump_dict\u001b[49m()\n\u001b[0;32m      3\u001b[0m background_info\u001b[38;5;241m.\u001b[39mmodel_dump_schema()\n\u001b[0;32m      5\u001b[0m background_info\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\pydantic\\main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InMemoryChatMessageHistory' object has no attribute 'model_dump_dict'"
     ]
    }
   ],
   "source": [
    "\n",
    "background_info.model_dump_json()\n",
    "background_info.model_dump_dict()\n",
    "background_info.model_dump_schema()\n",
    "\n",
    "background_info.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_h = HumanMessagePromptTemplate.from_template(template='{follow-up question}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(background_info.messages + [message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['follow-up question'], input_types={}, partial_variables={}, messages=[HumanMessage(content=\"Can you give me an interesting fact I probably didn't know about?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, did you know its 85', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['follow-up question'], input_types={}, partial_variables={}, template='{follow-up question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shett\\AppData\\Local\\Temp\\ipykernel_3176\\4193683424.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm= chat, prompt=chat_template)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm= chat, prompt=chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'follow-up question':'What is the name longest city name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'follow-up question': 'What is the name longest city name?',\n",
       " 'text': 'The longest city name in the world is \"Krungthepmahanakhon Amonrattanakosin Mahintharayutthaya Mahadilokphop Noppharatratchathaniburirom Udomratchaniwetmahasathan Amonphimanawatansathit Sakkathattiyawitsanukamban\" in Thailand. However, it\\'s commonly known as Bangkok.'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s = SystemMessage(content='''The chatbot should reluctantly answer questions with sarcastic responses''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_h = HumanMessagePromptTemplate.from_template(template='''{question}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = MessagesPlaceholder(variable_name='message_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_s, message_history, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['message_log', 'question'], input_types={'message_log': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001AEBD474790>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content='The chatbot should reluctantly answer questions with sarcastic responses', additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='message_log'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_info = ChatMessageHistory()\n",
    "background_info.add_user_message(\"Hi\")\n",
    "background_info.add_ai_message(\"You really how to make an entrance, don;t you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#String output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = \"Can you give me an interesting fact I probably didn't know about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 21, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-03ddf14a-effd-4fdb-9b2d-8cbf1092c34c-0', usage_metadata={'input_tokens': 21, 'output_tokens': 33, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_out_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_parsed = str_out_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n"
     ]
    }
   ],
   "source": [
    "print(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comma seperated parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = \"Could you suggest some dog names?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Could you suggest some dog names?' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(message_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bella\n",
      "2. Max\n",
      "3. Charlie\n",
      "4. Charlie\n",
      "5. Daisy\n",
      "6. Buddy\n",
      "7. Lucy\n",
      "8. Bailey\n",
      "9. Molly\n",
      "10. Cooper\n",
      "11. Lola\n",
      "12. Rocky\n",
      "13. Sadie\n",
      "14. Zeus\n",
      "15. Toby\n",
      "16. Daisy\n",
      "17. Winston\n",
      "18. Luna\n",
      "19. Ruby\n",
      "20. Jack\n",
      "21. Oliver\n",
      "22. Chloe\n",
      "23. Duke\n",
      "24. Roxy\n",
      "25.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ot_parser = CommaSeparatedListOutputParser()\n",
    "response_parsed = list_ot_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Bella',\n",
       " '2. Max',\n",
       " '3. Charlie',\n",
       " '4. Charlie',\n",
       " '5. Daisy',\n",
       " '6. Buddy',\n",
       " '7. Lucy',\n",
       " '8. Bailey',\n",
       " '9. Molly',\n",
       " '10. Cooper',\n",
       " '11. Lola',\n",
       " '12. Rocky',\n",
       " '13. Sadie',\n",
       " '14. Zeus',\n",
       " '15. Toby',\n",
       " '16. Daisy',\n",
       " '17. Winston',\n",
       " '18. Luna',\n",
       " '19. Ruby',\n",
       " '20. Jack',\n",
       " '21. Oliver',\n",
       " '22. Chloe',\n",
       " '23. Duke',\n",
       " '24. Roxy',\n",
       " '25.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date Time parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = f'''When was Mahatma Gandhiji was born?\n",
    "                         {DatetimeOutputParser().get_format_instructions()}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1869-10-02T00:00:00.000000Z' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 109, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ea833c9c-e84b-4973-8bc9-4d3ddb17cf69-0' usage_metadata={'input_tokens': 109, 'output_tokens': 16, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869-10-02T00:00:00.000000Z\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ot_parse = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_parsed = date_ot_parse.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869-10-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
