{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document loading using PyPDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docx2txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pypdf) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_pdf = PyPDFLoader(r\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_pdf = loader_pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 0}, page_content='Analysis vs Analytics \\nAlright! So… \\nLet’s discuss the not-so-obvious differences \\nbetween the terms analysis and analytics. \\nDue to the similarity of the words, some people \\nbelieve they share the same meaning, and thus \\nuse them interchangeably. Technically, this \\nisn’t correct. There is, in fact, a distinct \\ndifference between the two. And the reason \\nfor one often being used instead of the other \\nis the lack of a transparent understanding \\nof both. \\nSo, let’s clear this up, shall we? \\nFirst, we will start with analysis. \\nConsider the following… \\nYou have a huge dataset containing data of \\nvarious types. Instead of tackling the entire \\ndataset and running the risk of becoming overwhelmed, \\nyou separate it into easier to digest chunks \\nand study them individually and examine how \\nthey relate to other parts. And that’s analysis \\nin a nutshell. \\nOne important thing to remember, however, \\nis that you perform analyses on things that \\nhave already happened in the past. Such as \\nusing an analysis to explain how a story ended \\nthe way it did or how there was a decrease \\nin sales last summer. \\nAll this means that we do analyses to explain \\nhow and/or why something happened. \\nGreat! \\nNow, this leads us nicely on to the definition \\nof analytics. \\nAs you have probably guessed, analytics generally \\nrefers to the future. Instead of explaining \\npast events it explores potential future ones. \\nAnalytics is essentially the application of \\nlogical and computational reasoning to the \\ncomponent parts obtained in an analysis. And \\nin doing this you are looking for patterns '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 1}, page_content=\"and exploring what you could do with them \\nin the future. \\nHere, analytics branches off into two areas: \\nqualitative analytics – this is using your \\nintuition and experience in conjunction with \\nthe analysis to plan your next business move. \\nAnd quantitative analytics – this is applying \\nformulas and algorithms to numbers you have \\ngathered from your analysis. \\nHere are a couple of examples. \\nSay, you are an owner of an online clothing \\nstore. You are ahead of the competition and \\nhave a great understanding of what your customer's \\nneeds and wants are. You’ve performed a \\nvery detailed analysis from women’s clothing \\narticles and feel sure about which fashion \\ntrends to follow. You may use this intuition \\nto decide on which styles of clothing to start \\nselling. This would be qualitative analytics. \\nBut you might not know when to introduce the \\nnew collection. In that case, relying on past \\nsales data and user experience data, you could \\npredict in which month it would be best to \\ndo that. This is an example of using quantitative \\nanalytics. \\nFantastic! \\nTo backtrack a little, you can combine these \\nareas with analyses also – you could perform \\nqualitative analysis – to explain how or \\nwhy a story ended the way it did. And you \\ncan perform quantitative analysis – working \\nwith past data to explain how sales decreased \\nlast summer. \\nPerfect! \\nNow that we have cleared up the differences \\nbetween analysis and analytics it shouldn’t \\nbe too difficult to see how terms such as \\n‘data analysis’, ‘data analytics’, \\n‘business analysis’ and ‘business analytics’ \\ncan have their unique meanings too. \\nMore of this will be explained in the next \\nvideo which aims to simplify these, as well \"), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 2}, page_content='as many more with a fantastic diagram. So, \\nlet’s move on! \\nProgramming Languages & Software Employed in Data Science - All the Tools You \\nNeed \\nAlright! So… \\nHow are the techniques used in data, business \\nintelligence, or predictive analytics applied \\nin real life? \\nCertainly, with the help of computers. \\nYou can basically split the relevant tools \\ninto two categories—programming languages \\nand software. \\nKnowing a programming language enables you \\nto devise programs that can execute specific \\noperations. Moreover, you can reuse these \\nprograms whenever you need to execute the \\nsame action. \\nAs you can see from the infographic, R, and \\nPython are the two most popular tools across \\nall columns. Their biggest advantage is that \\nthey can manipulate data and are integrated \\nwithin multiple data and data science software \\nplatforms. They are not just suitable for \\nmathematical and statistical computations. \\nIn other words, R, and Python are adaptable. \\nThey can solve a wide variety of business \\nand data-related problems from beginning to \\nthe end. \\nOf course, R, and Python do have their limitations. \\nThey are not able to address problems specific \\nto some domains. One example is ‘relational \\ndatabase management systems’—there, SQL \\nis king. It was specifically created for that \\npurpose. SQL is at its most advantageous when \\nworking with traditional, historical data. \\nWhen preparing your BI analysis, for instance, \\nyou will surely employ it. \\nOkay. \\nWhen it comes to data science, mentioning '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 3}, page_content='MATLAB is inevitable. It is ideal for working \\nwith mathematical functions or matrix manipulations. \\nThat’s why it is present in all categories \\nexcept for ‘big data’. While respectable, \\nMATLAB usage is a paid service, and that’s \\none of the reasons why it is losing ground \\nto open-source languages like R and Python. \\nEither way, R, Python, and MATLAB, combined \\nwith SQL, cover most of the tools used when \\nworking with traditional data, BI, and conventional \\ndata science. \\nWhat about big data? \\nApart from R and Python, people working in \\nthis area are often proficient in other languages \\nlike Java or Scala. These two have not been \\ndeveloped specifically for doing statistical \\nanalyses, however they turn out to be very \\nuseful when combining data from multiple sources. \\nAll right! Let’s finish off with machine \\nlearning. \\nWhen it comes to machine learning, we often \\ndeal with big data. Thus, we need a lot of \\ncomputational power, and we can expect people \\nto use the languages similar to those in the \\nbig data column. Apart from R, Python, and \\nMATLAB, other, faster languages are used like \\nJava, JavaScript, C, C++, and Scala. \\nCool. \\nWhat we said may be wonderful, but that’s \\nnot all! \\nBy using one or more programming languages, \\npeople create application software or, as \\nthey are sometimes called, software solutions, \\nthat are adjusted for specific business needs. \\nTheir smaller scope does not make them less \\nuseful, in fact, just the opposite—they \\nare a lot easier to learn and be adopted by \\nothers. You have already heard of several \\nof those. \\nBecause of its ability to do relatively complex \\ncomputations and good visualizations quickly, \\nExcel is a tool applicable to more than one '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 4}, page_content='category—traditional data, BI, and Data \\nScience. Similarly, SPSS is a very famous \\ntool for working with traditional data and \\napplying statistical analysis. \\nAmong the many applications we have plotted, \\nwe can say there is an increasing amount of \\nsoftware designed for working with big data \\nsuch as Apache Hadoop, Apache Hbase, and Mongo \\nDB. \\nIn terms of big data, Hadoop is the name that \\nmust stick with you. Hadoop is listed as a \\nsoftware in the sense that it is a collection \\nof programs, but don’t imagine it as a nice-looking \\napplication. It’s actually a software framework \\nwhich was designed to address the complexity \\nof big data and its computational intensity. \\nMost notably, Hadoop distributes the computational \\ntasks on multiple computers which is basically \\nthe way to handle big data nowadays. \\nPower BI, SaS, Qlik, and especially Tableau \\nare top-notch examples of software designed \\nfor business intelligence visualizations. \\nIn terms of predictive analytics, EViews is \\nmostly used for working with econometric time-series \\nmodels, and Stata—for academic statistical \\nand econometric research, where techniques \\nlike regression, cluster, and factor analysis \\nare constantly applied. \\nAs a final note, remember the following. \\nShould you have the relevant business and \\ntheoretical knowledge, learning a software \\ntool is relatively easy as opposed to learning \\na programming language. More importantly, \\nit will be sufficient for your need to create \\nquick and accurate analyses. \\nHowever, if your theoretical preparation is \\nstrong enough, you will find yourself restricted \\nby software. Knowing a programming language \\nsuch as R and Python, gives you the freedom \\nto create specific, ad-hoc tools for each \\nproject you are working on. \\nGreat! '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 5}, page_content='We hope we gave you a good idea about the \\nlevel of applicability of the most frequently \\nused programming and software tools in the \\nfield of data science. \\nThank you for watching! ')]\n"
     ]
    }
   ],
   "source": [
    "print(pages_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 0}, page_content='Analysis vs Analytics \\nAlright! So… \\nLet’s discuss the not-so-obvious differences \\nbetween the terms analysis and analytics. \\nDue to the similarity of the words, some people \\nbelieve they share the same meaning, and thus \\nuse them interchangeably. Technically, this \\nisn’t correct. There is, in fact, a distinct \\ndifference between the two. And the reason \\nfor one often being used instead of the other \\nis the lack of a transparent understanding \\nof both. \\nSo, let’s clear this up, shall we? \\nFirst, we will start with analysis. \\nConsider the following… \\nYou have a huge dataset containing data of \\nvarious types. Instead of tackling the entire \\ndataset and running the risk of becoming overwhelmed, \\nyou separate it into easier to digest chunks \\nand study them individually and examine how \\nthey relate to other parts. And that’s analysis \\nin a nutshell. \\nOne important thing to remember, however, \\nis that you perform analyses on things that \\nhave already happened in the past. Such as \\nusing an analysis to explain how a story ended \\nthe way it did or how there was a decrease \\nin sales last summer. \\nAll this means that we do analyses to explain \\nhow and/or why something happened. \\nGreat! \\nNow, this leads us nicely on to the definition \\nof analytics. \\nAs you have probably guessed, analytics generally \\nrefers to the future. Instead of explaining \\npast events it explores potential future ones. \\nAnalytics is essentially the application of \\nlogical and computational reasoning to the \\ncomponent parts obtained in an analysis. And \\nin doing this you are looking for patterns '),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 1}, page_content=\"and exploring what you could do with them \\nin the future. \\nHere, analytics branches off into two areas: \\nqualitative analytics – this is using your \\nintuition and experience in conjunction with \\nthe analysis to plan your next business move. \\nAnd quantitative analytics – this is applying \\nformulas and algorithms to numbers you have \\ngathered from your analysis. \\nHere are a couple of examples. \\nSay, you are an owner of an online clothing \\nstore. You are ahead of the competition and \\nhave a great understanding of what your customer's \\nneeds and wants are. You’ve performed a \\nvery detailed analysis from women’s clothing \\narticles and feel sure about which fashion \\ntrends to follow. You may use this intuition \\nto decide on which styles of clothing to start \\nselling. This would be qualitative analytics. \\nBut you might not know when to introduce the \\nnew collection. In that case, relying on past \\nsales data and user experience data, you could \\npredict in which month it would be best to \\ndo that. This is an example of using quantitative \\nanalytics. \\nFantastic! \\nTo backtrack a little, you can combine these \\nareas with analyses also – you could perform \\nqualitative analysis – to explain how or \\nwhy a story ended the way it did. And you \\ncan perform quantitative analysis – working \\nwith past data to explain how sales decreased \\nlast summer. \\nPerfect! \\nNow that we have cleared up the differences \\nbetween analysis and analytics it shouldn’t \\nbe too difficult to see how terms such as \\n‘data analysis’, ‘data analytics’, \\n‘business analysis’ and ‘business analytics’ \\ncan have their unique meanings too. \\nMore of this will be explained in the next \\nvideo which aims to simplify these, as well \"),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 2}, page_content='as many more with a fantastic diagram. So, \\nlet’s move on! \\nProgramming Languages & Software Employed in Data Science - All the Tools You \\nNeed \\nAlright! So… \\nHow are the techniques used in data, business \\nintelligence, or predictive analytics applied \\nin real life? \\nCertainly, with the help of computers. \\nYou can basically split the relevant tools \\ninto two categories—programming languages \\nand software. \\nKnowing a programming language enables you \\nto devise programs that can execute specific \\noperations. Moreover, you can reuse these \\nprograms whenever you need to execute the \\nsame action. \\nAs you can see from the infographic, R, and \\nPython are the two most popular tools across \\nall columns. Their biggest advantage is that \\nthey can manipulate data and are integrated \\nwithin multiple data and data science software \\nplatforms. They are not just suitable for \\nmathematical and statistical computations. \\nIn other words, R, and Python are adaptable. \\nThey can solve a wide variety of business \\nand data-related problems from beginning to \\nthe end. \\nOf course, R, and Python do have their limitations. \\nThey are not able to address problems specific \\nto some domains. One example is ‘relational \\ndatabase management systems’—there, SQL \\nis king. It was specifically created for that \\npurpose. SQL is at its most advantageous when \\nworking with traditional, historical data. \\nWhen preparing your BI analysis, for instance, \\nyou will surely employ it. \\nOkay. \\nWhen it comes to data science, mentioning '),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 3}, page_content='MATLAB is inevitable. It is ideal for working \\nwith mathematical functions or matrix manipulations. \\nThat’s why it is present in all categories \\nexcept for ‘big data’. While respectable, \\nMATLAB usage is a paid service, and that’s \\none of the reasons why it is losing ground \\nto open-source languages like R and Python. \\nEither way, R, Python, and MATLAB, combined \\nwith SQL, cover most of the tools used when \\nworking with traditional data, BI, and conventional \\ndata science. \\nWhat about big data? \\nApart from R and Python, people working in \\nthis area are often proficient in other languages \\nlike Java or Scala. These two have not been \\ndeveloped specifically for doing statistical \\nanalyses, however they turn out to be very \\nuseful when combining data from multiple sources. \\nAll right! Let’s finish off with machine \\nlearning. \\nWhen it comes to machine learning, we often \\ndeal with big data. Thus, we need a lot of \\ncomputational power, and we can expect people \\nto use the languages similar to those in the \\nbig data column. Apart from R, Python, and \\nMATLAB, other, faster languages are used like \\nJava, JavaScript, C, C++, and Scala. \\nCool. \\nWhat we said may be wonderful, but that’s \\nnot all! \\nBy using one or more programming languages, \\npeople create application software or, as \\nthey are sometimes called, software solutions, \\nthat are adjusted for specific business needs. \\nTheir smaller scope does not make them less \\nuseful, in fact, just the opposite—they \\nare a lot easier to learn and be adopted by \\nothers. You have already heard of several \\nof those. \\nBecause of its ability to do relatively complex \\ncomputations and good visualizations quickly, \\nExcel is a tool applicable to more than one '),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 4}, page_content='category—traditional data, BI, and Data \\nScience. Similarly, SPSS is a very famous \\ntool for working with traditional data and \\napplying statistical analysis. \\nAmong the many applications we have plotted, \\nwe can say there is an increasing amount of \\nsoftware designed for working with big data \\nsuch as Apache Hadoop, Apache Hbase, and Mongo \\nDB. \\nIn terms of big data, Hadoop is the name that \\nmust stick with you. Hadoop is listed as a \\nsoftware in the sense that it is a collection \\nof programs, but don’t imagine it as a nice-looking \\napplication. It’s actually a software framework \\nwhich was designed to address the complexity \\nof big data and its computational intensity. \\nMost notably, Hadoop distributes the computational \\ntasks on multiple computers which is basically \\nthe way to handle big data nowadays. \\nPower BI, SaS, Qlik, and especially Tableau \\nare top-notch examples of software designed \\nfor business intelligence visualizations. \\nIn terms of predictive analytics, EViews is \\nmostly used for working with econometric time-series \\nmodels, and Stata—for academic statistical \\nand econometric research, where techniques \\nlike regression, cluster, and factor analysis \\nare constantly applied. \\nAs a final note, remember the following. \\nShould you have the relevant business and \\ntheoretical knowledge, learning a software \\ntool is relatively easy as opposed to learning \\na programming language. More importantly, \\nit will be sufficient for your need to create \\nquick and accurate analyses. \\nHowever, if your theoretical preparation is \\nstrong enough, you will find yourself restricted \\nby software. Knowing a programming language \\nsuch as R and Python, gives you the freedom \\nto create specific, ad-hoc tools for each \\nproject you are working on. \\nGreat! '),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 5}, page_content='We hope we gave you a good idea about the \\nlevel of applicability of the most frequently \\nused programming and software tools in the \\nfield of data science. \\nThank you for watching! ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_pdf_cut = copy.deepcopy(pages_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 0}, page_content='Analysis vs Analytics \\nAlright! So… \\nLet’s discuss the not-so-obvious differences \\nbetween the terms analysis and analytics. \\nDue to the similarity of the words, some people \\nbelieve they share the same meaning, and thus \\nuse them interchangeably. Technically, this \\nisn’t correct. There is, in fact, a distinct \\ndifference between the two. And the reason \\nfor one often being used instead of the other \\nis the lack of a transparent understanding \\nof both. \\nSo, let’s clear this up, shall we? \\nFirst, we will start with analysis. \\nConsider the following… \\nYou have a huge dataset containing data of \\nvarious types. Instead of tackling the entire \\ndataset and running the risk of becoming overwhelmed, \\nyou separate it into easier to digest chunks \\nand study them individually and examine how \\nthey relate to other parts. And that’s analysis \\nin a nutshell. \\nOne important thing to remember, however, \\nis that you perform analyses on things that \\nhave already happened in the past. Such as \\nusing an analysis to explain how a story ended \\nthe way it did or how there was a decrease \\nin sales last summer. \\nAll this means that we do analyses to explain \\nhow and/or why something happened. \\nGreat! \\nNow, this leads us nicely on to the definition \\nof analytics. \\nAs you have probably guessed, analytics generally \\nrefers to the future. Instead of explaining \\npast events it explores potential future ones. \\nAnalytics is essentially the application of \\nlogical and computational reasoning to the \\ncomponent parts obtained in an analysis. And \\nin doing this you are looking for patterns '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 1}, page_content=\"and exploring what you could do with them \\nin the future. \\nHere, analytics branches off into two areas: \\nqualitative analytics – this is using your \\nintuition and experience in conjunction with \\nthe analysis to plan your next business move. \\nAnd quantitative analytics – this is applying \\nformulas and algorithms to numbers you have \\ngathered from your analysis. \\nHere are a couple of examples. \\nSay, you are an owner of an online clothing \\nstore. You are ahead of the competition and \\nhave a great understanding of what your customer's \\nneeds and wants are. You’ve performed a \\nvery detailed analysis from women’s clothing \\narticles and feel sure about which fashion \\ntrends to follow. You may use this intuition \\nto decide on which styles of clothing to start \\nselling. This would be qualitative analytics. \\nBut you might not know when to introduce the \\nnew collection. In that case, relying on past \\nsales data and user experience data, you could \\npredict in which month it would be best to \\ndo that. This is an example of using quantitative \\nanalytics. \\nFantastic! \\nTo backtrack a little, you can combine these \\nareas with analyses also – you could perform \\nqualitative analysis – to explain how or \\nwhy a story ended the way it did. And you \\ncan perform quantitative analysis – working \\nwith past data to explain how sales decreased \\nlast summer. \\nPerfect! \\nNow that we have cleared up the differences \\nbetween analysis and analytics it shouldn’t \\nbe too difficult to see how terms such as \\n‘data analysis’, ‘data analytics’, \\n‘business analysis’ and ‘business analytics’ \\ncan have their unique meanings too. \\nMore of this will be explained in the next \\nvideo which aims to simplify these, as well \"), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 2}, page_content='as many more with a fantastic diagram. So, \\nlet’s move on! \\nProgramming Languages & Software Employed in Data Science - All the Tools You \\nNeed \\nAlright! So… \\nHow are the techniques used in data, business \\nintelligence, or predictive analytics applied \\nin real life? \\nCertainly, with the help of computers. \\nYou can basically split the relevant tools \\ninto two categories—programming languages \\nand software. \\nKnowing a programming language enables you \\nto devise programs that can execute specific \\noperations. Moreover, you can reuse these \\nprograms whenever you need to execute the \\nsame action. \\nAs you can see from the infographic, R, and \\nPython are the two most popular tools across \\nall columns. Their biggest advantage is that \\nthey can manipulate data and are integrated \\nwithin multiple data and data science software \\nplatforms. They are not just suitable for \\nmathematical and statistical computations. \\nIn other words, R, and Python are adaptable. \\nThey can solve a wide variety of business \\nand data-related problems from beginning to \\nthe end. \\nOf course, R, and Python do have their limitations. \\nThey are not able to address problems specific \\nto some domains. One example is ‘relational \\ndatabase management systems’—there, SQL \\nis king. It was specifically created for that \\npurpose. SQL is at its most advantageous when \\nworking with traditional, historical data. \\nWhen preparing your BI analysis, for instance, \\nyou will surely employ it. \\nOkay. \\nWhen it comes to data science, mentioning '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 3}, page_content='MATLAB is inevitable. It is ideal for working \\nwith mathematical functions or matrix manipulations. \\nThat’s why it is present in all categories \\nexcept for ‘big data’. While respectable, \\nMATLAB usage is a paid service, and that’s \\none of the reasons why it is losing ground \\nto open-source languages like R and Python. \\nEither way, R, Python, and MATLAB, combined \\nwith SQL, cover most of the tools used when \\nworking with traditional data, BI, and conventional \\ndata science. \\nWhat about big data? \\nApart from R and Python, people working in \\nthis area are often proficient in other languages \\nlike Java or Scala. These two have not been \\ndeveloped specifically for doing statistical \\nanalyses, however they turn out to be very \\nuseful when combining data from multiple sources. \\nAll right! Let’s finish off with machine \\nlearning. \\nWhen it comes to machine learning, we often \\ndeal with big data. Thus, we need a lot of \\ncomputational power, and we can expect people \\nto use the languages similar to those in the \\nbig data column. Apart from R, Python, and \\nMATLAB, other, faster languages are used like \\nJava, JavaScript, C, C++, and Scala. \\nCool. \\nWhat we said may be wonderful, but that’s \\nnot all! \\nBy using one or more programming languages, \\npeople create application software or, as \\nthey are sometimes called, software solutions, \\nthat are adjusted for specific business needs. \\nTheir smaller scope does not make them less \\nuseful, in fact, just the opposite—they \\nare a lot easier to learn and be adopted by \\nothers. You have already heard of several \\nof those. \\nBecause of its ability to do relatively complex \\ncomputations and good visualizations quickly, \\nExcel is a tool applicable to more than one '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 4}, page_content='category—traditional data, BI, and Data \\nScience. Similarly, SPSS is a very famous \\ntool for working with traditional data and \\napplying statistical analysis. \\nAmong the many applications we have plotted, \\nwe can say there is an increasing amount of \\nsoftware designed for working with big data \\nsuch as Apache Hadoop, Apache Hbase, and Mongo \\nDB. \\nIn terms of big data, Hadoop is the name that \\nmust stick with you. Hadoop is listed as a \\nsoftware in the sense that it is a collection \\nof programs, but don’t imagine it as a nice-looking \\napplication. It’s actually a software framework \\nwhich was designed to address the complexity \\nof big data and its computational intensity. \\nMost notably, Hadoop distributes the computational \\ntasks on multiple computers which is basically \\nthe way to handle big data nowadays. \\nPower BI, SaS, Qlik, and especially Tableau \\nare top-notch examples of software designed \\nfor business intelligence visualizations. \\nIn terms of predictive analytics, EViews is \\nmostly used for working with econometric time-series \\nmodels, and Stata—for academic statistical \\nand econometric research, where techniques \\nlike regression, cluster, and factor analysis \\nare constantly applied. \\nAs a final note, remember the following. \\nShould you have the relevant business and \\ntheoretical knowledge, learning a software \\ntool is relatively easy as opposed to learning \\na programming language. More importantly, \\nit will be sufficient for your need to create \\nquick and accurate analyses. \\nHowever, if your theoretical preparation is \\nstrong enough, you will find yourself restricted \\nby software. Knowing a programming language \\nsuch as R and Python, gives you the freedom \\nto create specific, ad-hoc tools for each \\nproject you are working on. \\nGreat! '), Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 5}, page_content='We hope we gave you a good idea about the \\nlevel of applicability of the most frequently \\nused programming and software tools in the \\nfield of data science. \\nThank you for watching! ')]\n"
     ]
    }
   ],
   "source": [
    "print(pages_pdf_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analysis',\n",
       " 'vs',\n",
       " 'Analytics',\n",
       " 'Alright!',\n",
       " 'So…',\n",
       " 'Let’s',\n",
       " 'discuss',\n",
       " 'the',\n",
       " 'not-so-obvious',\n",
       " 'differences',\n",
       " 'between',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'analytics.',\n",
       " 'Due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'similarity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'words,',\n",
       " 'some',\n",
       " 'people',\n",
       " 'believe',\n",
       " 'they',\n",
       " 'share',\n",
       " 'the',\n",
       " 'same',\n",
       " 'meaning,',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'use',\n",
       " 'them',\n",
       " 'interchangeably.',\n",
       " 'Technically,',\n",
       " 'this',\n",
       " 'isn’t',\n",
       " 'correct.',\n",
       " 'There',\n",
       " 'is,',\n",
       " 'in',\n",
       " 'fact,',\n",
       " 'a',\n",
       " 'distinct',\n",
       " 'difference',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'one',\n",
       " 'often',\n",
       " 'being',\n",
       " 'used',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'is',\n",
       " 'the',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'a',\n",
       " 'transparent',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'both.',\n",
       " 'So,',\n",
       " 'let’s',\n",
       " 'clear',\n",
       " 'this',\n",
       " 'up,',\n",
       " 'shall',\n",
       " 'we?',\n",
       " 'First,',\n",
       " 'we',\n",
       " 'will',\n",
       " 'start',\n",
       " 'with',\n",
       " 'analysis.',\n",
       " 'Consider',\n",
       " 'the',\n",
       " 'following…',\n",
       " 'You',\n",
       " 'have',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'dataset',\n",
       " 'containing',\n",
       " 'data',\n",
       " 'of',\n",
       " 'various',\n",
       " 'types.',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'tackling',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'dataset',\n",
       " 'and',\n",
       " 'running',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'becoming',\n",
       " 'overwhelmed,',\n",
       " 'you',\n",
       " 'separate',\n",
       " 'it',\n",
       " 'into',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'digest',\n",
       " 'chunks',\n",
       " 'and',\n",
       " 'study',\n",
       " 'them',\n",
       " 'individually',\n",
       " 'and',\n",
       " 'examine',\n",
       " 'how',\n",
       " 'they',\n",
       " 'relate',\n",
       " 'to',\n",
       " 'other',\n",
       " 'parts.',\n",
       " 'And',\n",
       " 'that’s',\n",
       " 'analysis',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nutshell.',\n",
       " 'One',\n",
       " 'important',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'remember,',\n",
       " 'however,',\n",
       " 'is',\n",
       " 'that',\n",
       " 'you',\n",
       " 'perform',\n",
       " 'analyses',\n",
       " 'on',\n",
       " 'things',\n",
       " 'that',\n",
       " 'have',\n",
       " 'already',\n",
       " 'happened',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past.',\n",
       " 'Such',\n",
       " 'as',\n",
       " 'using',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'how',\n",
       " 'a',\n",
       " 'story',\n",
       " 'ended',\n",
       " 'the',\n",
       " 'way',\n",
       " 'it',\n",
       " 'did',\n",
       " 'or',\n",
       " 'how',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'decrease',\n",
       " 'in',\n",
       " 'sales',\n",
       " 'last',\n",
       " 'summer.',\n",
       " 'All',\n",
       " 'this',\n",
       " 'means',\n",
       " 'that',\n",
       " 'we',\n",
       " 'do',\n",
       " 'analyses',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'how',\n",
       " 'and/or',\n",
       " 'why',\n",
       " 'something',\n",
       " 'happened.',\n",
       " 'Great!',\n",
       " 'Now,',\n",
       " 'this',\n",
       " 'leads',\n",
       " 'us',\n",
       " 'nicely',\n",
       " 'on',\n",
       " 'to',\n",
       " 'the',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'analytics.',\n",
       " 'As',\n",
       " 'you',\n",
       " 'have',\n",
       " 'probably',\n",
       " 'guessed,',\n",
       " 'analytics',\n",
       " 'generally',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'future.',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'explaining',\n",
       " 'past',\n",
       " 'events',\n",
       " 'it',\n",
       " 'explores',\n",
       " 'potential',\n",
       " 'future',\n",
       " 'ones.',\n",
       " 'Analytics',\n",
       " 'is',\n",
       " 'essentially',\n",
       " 'the',\n",
       " 'application',\n",
       " 'of',\n",
       " 'logical',\n",
       " 'and',\n",
       " 'computational',\n",
       " 'reasoning',\n",
       " 'to',\n",
       " 'the',\n",
       " 'component',\n",
       " 'parts',\n",
       " 'obtained',\n",
       " 'in',\n",
       " 'an',\n",
       " 'analysis.',\n",
       " 'And',\n",
       " 'in',\n",
       " 'doing',\n",
       " 'this',\n",
       " 'you',\n",
       " 'are',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'patterns']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf_cut[0].page_content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(pages_pdf_cut[0].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pages_pdf_cut:\n",
    "    i.page_content = ' '.join(pages_pdf_cut[0].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 0}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 1}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 2}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 3}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 4}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.pdf', 'page': 5}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Analysis vs Analytics \\nAlright! So… \\nLet’s discuss the not-so-obvious differences \\nbetween the terms analysis and analytics. \\nDue to the similarity of the words, some people \\nbelieve they share the same meaning, and thus \\nuse them interchangeably. Technically, this \\nisn’t correct. There is, in fact, a distinct \\ndifference between the two. And the reason \\nfor one often being used instead of the other \\nis the lack of a transparent understanding \\nof both. \\nSo, let’s clear this up, shall we? \\nFirst, we will start with analysis. \\nConsider the following… \\nYou have a huge dataset containing data of \\nvarious types. Instead of tackling the entire \\ndataset and running the risk of becoming overwhelmed, \\nyou separate it into easier to digest chunks \\nand study them individually and examine how \\nthey relate to other parts. And that’s analysis \\nin a nutshell. \\nOne important thing to remember, however, \\nis that you perform analyses on things that \\nhave already happened in the past. Such as \\nusing an analysis to explain how a story ended \\nthe way it did or how there was a decrease \\nin sales last summer. \\nAll this means that we do analyses to explain \\nhow and/or why something happened. \\nGreat! \\nNow, this leads us nicely on to the definition \\nof analytics. \\nAs you have probably guessed, analytics generally \\nrefers to the future. Instead of explaining \\npast events it explores potential future ones. \\nAnalytics is essentially the application of \\nlogical and computational reasoning to the \\ncomponent parts obtained in an analysis. And \\nin doing this you are looking for patterns ',\n",
       " 'Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf[0].page_content, pages_pdf_cut[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check token efficiency open platfor.openai.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading with DOCx2txt loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_docx = Docx2txtLoader(r\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_docx = loader_docx.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science.docx'}, page_content=\"Analysis vs Analytics\\n\\nAlright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!\\n\\nProgramming Languages & Software Employed in Data Science - All the Tools You Need\\n\\nAlright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!\")]\n"
     ]
    }
   ],
   "source": [
    "print(pages_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentv splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Docx2txtLoader(\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pages)):\n",
    "    pages[i].page_content = ' '.join(pages[i].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move. And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow. You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics. Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer. Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram. So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations. Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end. Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data. When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable. It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs. Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis. Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application. It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations. In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language. More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on. Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8259"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_splitter = CharacterTextSplitter(separator = \"\", chunk_size= 500, chunk_overlap = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_char_split = char_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_char_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.518"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8259/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.518*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_char_split[16].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doc splitting with langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Heading1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Heading 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_docx = Docx2txtLoader(r\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader_docx.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\shett\\\\Downloads\\\\Introduction_to_Data_and_Data_Science2.docx'}, page_content=\"#Intoduction to Data and Data Science\\n\\n\\n\\n\\n\\n##Analysis vs Analytics\\n\\nAlright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!\\n\\nProgramming Languages & Software Employed in Data Science - All the Tools You Need\\n\\nAlright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!\")]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[('#', \"Course Title\"),(\"##\", \"Lecture Title\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_md_split = md_splitter.split_text(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"#Intoduction to Data and Data Science  \\n##Analysis vs Analytics  \\nAlright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!  \\nProgramming Languages & Software Employed in Data Science - All the Tools You Need  \\nAlright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!\")]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_md_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text embedding with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters.character import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_docx = Docx2txtLoader(r\"filepath\")\n",
    "pages = loader_docx.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[('#', \"Course Title\"), (\"##\", \"Lecture Title\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_md_split = md_splitter.split_text(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pages_md_split)):\n",
    "    pages_md_split[i].page_content = ' '.join(pages_md_split[i].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\".\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_char_split = char_splitter.split_documents(pages_md_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='#Intoduction to Data and Data Science ##Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both'),\n",
       " Document(metadata={}, page_content='So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell'),\n",
       " Document(metadata={}, page_content='And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future'),\n",
       " Document(metadata={}, page_content='Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move'),\n",
       " Document(metadata={}, page_content=\"And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow\"),\n",
       " Document(metadata={}, page_content='You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics'),\n",
       " Document(metadata={}, page_content='Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer'),\n",
       " Document(metadata={}, page_content='Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram'),\n",
       " Document(metadata={}, page_content='So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations'),\n",
       " Document(metadata={}, page_content='Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable'),\n",
       " Document(metadata={}, page_content='In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end. Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data'),\n",
       " Document(metadata={}, page_content='When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable. It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python'),\n",
       " Document(metadata={}, page_content='Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning'),\n",
       " Document(metadata={}, page_content='All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool'),\n",
       " Document(metadata={}, page_content='Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs. Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those'),\n",
       " Document(metadata={}, page_content='You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis'),\n",
       " Document(metadata={}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application'),\n",
       " Document(metadata={}, page_content='It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations'),\n",
       " Document(metadata={}, page_content='In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language'),\n",
       " Document(metadata={}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on'),\n",
       " Document(metadata={}, page_content='Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_char_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1= embedding.embed_query(pages_char_split[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2= embedding.embed_query(pages_char_split[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector3= embedding.embed_query(pages_char_split[18].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0009598906035535038,\n",
       " 0.001555573078803718,\n",
       " 0.00980286207050085,\n",
       " -0.02683161199092865,\n",
       " -0.022208597511053085,\n",
       " 0.014477674849331379,\n",
       " -0.026391325518488884,\n",
       " -0.014322279952466488,\n",
       " 0.002094601048156619,\n",
       " -0.01853090524673462,\n",
       " 0.007187039125710726,\n",
       " 0.022105000913143158,\n",
       " -0.008805741555988789,\n",
       " 0.0011808434501290321,\n",
       " -0.009822286665439606,\n",
       " -0.02249348908662796,\n",
       " 0.040972597897052765,\n",
       " -0.01149278786033392,\n",
       " 0.01417983416467905,\n",
       " -0.019346732646226883,\n",
       " -0.035533756017684937,\n",
       " 0.0159927811473608,\n",
       " -0.0017838100902736187,\n",
       " -0.024940967559814453,\n",
       " -0.01322803646326065,\n",
       " 0.002340643899515271,\n",
       " 0.009615092538297176,\n",
       " -0.026935208588838577,\n",
       " 0.00833308044821024,\n",
       " -0.01048271730542183,\n",
       " 0.007484880276024342,\n",
       " 0.008825166150927544,\n",
       " -0.008864014409482479,\n",
       " -0.004597114864736795,\n",
       " -0.006562219932675362,\n",
       " -0.004917618352919817,\n",
       " 0.013389906845986843,\n",
       " 0.011097824200987816,\n",
       " 0.017119398340582848,\n",
       " 0.014529473148286343,\n",
       " 0.006552507635205984,\n",
       " -0.0008109699701890349,\n",
       " -0.028515063226222992,\n",
       " -0.02714240364730358,\n",
       " 0.014063287526369095,\n",
       " 0.013253935612738132,\n",
       " 0.014011488296091557,\n",
       " -0.013247461058199406,\n",
       " -0.0033798508811742067,\n",
       " 0.005231646355241537,\n",
       " 0.020576946437358856,\n",
       " 0.02290787734091282,\n",
       " -0.043743815273046494,\n",
       " 0.004758985247462988,\n",
       " 0.005474451929330826,\n",
       " -0.016199974343180656,\n",
       " -0.01316976360976696,\n",
       " 0.0056784083135426044,\n",
       " 0.0069863200187683105,\n",
       " 0.0025947801768779755,\n",
       " 0.013687748461961746,\n",
       " 0.015656091272830963,\n",
       " 0.003297297051176429,\n",
       " -0.00522517180070281,\n",
       " -0.015384148806333542,\n",
       " -0.018634503707289696,\n",
       " -0.01430932991206646,\n",
       " 0.027582690119743347,\n",
       " -1.2734635674860328e-05,\n",
       " 0.0028133050072938204,\n",
       " 0.01746903732419014,\n",
       " 0.021703563630580902,\n",
       " -0.005445315036922693,\n",
       " 0.009563294239342213,\n",
       " 0.02657262049615383,\n",
       " -0.007562578190118074,\n",
       " -0.016536664217710495,\n",
       " -0.025316506624221802,\n",
       " -0.012476958334445953,\n",
       " 0.017520835623145103,\n",
       " -0.009142431430518627,\n",
       " -0.003642080584540963,\n",
       " -0.014555373229086399,\n",
       " 2.6430377602082444e-06,\n",
       " -0.01084530632942915,\n",
       " 0.012884872034192085,\n",
       " -0.015034508891403675,\n",
       " 0.011117248795926571,\n",
       " -0.017443137243390083,\n",
       " 0.00826185755431652,\n",
       " -0.007426606956869364,\n",
       " -0.013364007696509361,\n",
       " 0.018517956137657166,\n",
       " 0.026210030540823936,\n",
       " -0.0062093427404761314,\n",
       " 0.01171940565109253,\n",
       " -0.011868326924741268,\n",
       " 0.0038686988409608603,\n",
       " 0.002936326200142503,\n",
       " -0.016886305063962936,\n",
       " 0.0057852426543831825,\n",
       " 0.024979816749691963,\n",
       " -0.03913374990224838,\n",
       " -0.008967611938714981,\n",
       " -0.023814350366592407,\n",
       " 0.0014503573765978217,\n",
       " 0.004147115629166365,\n",
       " 0.005668696016073227,\n",
       " 0.03672512248158455,\n",
       " -0.007245312444865704,\n",
       " -0.01701579988002777,\n",
       " 0.03504167124629021,\n",
       " 0.005192797631025314,\n",
       " -0.012185592204332352,\n",
       " 0.009168330579996109,\n",
       " -0.035456057637929916,\n",
       " 0.022959675639867783,\n",
       " -0.01784457638859749,\n",
       " -0.01648486591875553,\n",
       " -0.012476958334445953,\n",
       " 0.01719709485769272,\n",
       " 0.007666174788028002,\n",
       " 0.005590998567640781,\n",
       " 0.0018696014303714037,\n",
       " 0.011369766667485237,\n",
       " 0.00492085563018918,\n",
       " -0.014646019786596298,\n",
       " 0.002732369815930724,\n",
       " -0.02374960295855999,\n",
       " -0.02481147088110447,\n",
       " -0.0007951876032166183,\n",
       " -0.011110774241387844,\n",
       " -0.016834506765007973,\n",
       " 0.026779813691973686,\n",
       " -0.03866756334900856,\n",
       " -0.01329925935715437,\n",
       " -0.013202137313783169,\n",
       " 0.0007628135499544442,\n",
       " -0.007400707807391882,\n",
       " -0.027738085016608238,\n",
       " -0.014607171528041363,\n",
       " 0.003166181966662407,\n",
       " 0.0009785057045519352,\n",
       " 0.005552149377763271,\n",
       " -0.02549780160188675,\n",
       " 0.03146757557988167,\n",
       " 0.011706456542015076,\n",
       " 0.023322265595197678,\n",
       " 0.012541706673800945,\n",
       " -0.006432723719626665,\n",
       " 0.03211505711078644,\n",
       " -0.019087739288806915,\n",
       " -0.001156562939286232,\n",
       " 0.0062093427404761314,\n",
       " -0.007167614530771971,\n",
       " 0.013247461058199406,\n",
       " -0.0007595761562697589,\n",
       " 0.0060766092501580715,\n",
       " -0.01564314030110836,\n",
       " 0.009110057726502419,\n",
       " 0.008520849980413914,\n",
       " 0.0010343508329242468,\n",
       " 0.009854660369455814,\n",
       " 0.012081995606422424,\n",
       " 0.027349596843123436,\n",
       " 0.03413519635796547,\n",
       " 0.028100674971938133,\n",
       " 0.0028537726029753685,\n",
       " 0.005095675587654114,\n",
       " -0.021587016060948372,\n",
       " -0.011440989561378956,\n",
       " 0.020046012476086617,\n",
       " -0.02112082950770855,\n",
       " 0.019346732646226883,\n",
       " 0.006115457974374294,\n",
       " -0.00530934426933527,\n",
       " 0.007478405721485615,\n",
       " 0.0012561131734400988,\n",
       " -0.02204025350511074,\n",
       " -0.011745304800570011,\n",
       " 0.035533756017684937,\n",
       " -0.01195249892771244,\n",
       " 0.0025348879862576723,\n",
       " -0.000584351597353816,\n",
       " 4.6562989155063406e-05,\n",
       " -0.01041149441152811,\n",
       " 0.0124640092253685,\n",
       " 0.010340271517634392,\n",
       " -0.010061854496598244,\n",
       " -0.02926614135503769,\n",
       " -0.006423011422157288,\n",
       " 0.013402856886386871,\n",
       " 0.005519775673747063,\n",
       " 0.012593504972755909,\n",
       " -0.6580479145050049,\n",
       " -0.014063287526369095,\n",
       " 0.011570485308766365,\n",
       " -0.028981249779462814,\n",
       " 0.027660388499498367,\n",
       " 0.0002828682481776923,\n",
       " 0.02504456415772438,\n",
       " -0.02698700875043869,\n",
       " -0.01229566428810358,\n",
       " 0.017728028818964958,\n",
       " 0.019281983375549316,\n",
       " 0.0038298501167446375,\n",
       " 0.022920826449990273,\n",
       " -0.017417239025235176,\n",
       " -0.02394384704530239,\n",
       " -0.02812657505273819,\n",
       " -0.015889184549450874,\n",
       " -0.04439129680395126,\n",
       " 0.0005863749538548291,\n",
       " 0.016277672722935677,\n",
       " -0.018699251115322113,\n",
       " 0.03320282697677612,\n",
       " -0.012891346588730812,\n",
       " -0.0012245484394952655,\n",
       " -0.005218696780502796,\n",
       " 0.0038945982232689857,\n",
       " 0.021302124485373497,\n",
       " 0.015539543703198433,\n",
       " -0.008812216110527515,\n",
       " 0.01410213578492403,\n",
       " -0.013933790847659111,\n",
       " -0.005982724484056234,\n",
       " 0.004966179374605417,\n",
       " -0.007938116788864136,\n",
       " 0.04172367602586746,\n",
       " -0.003914022818207741,\n",
       " -0.004412583075463772,\n",
       " 0.033487718552351,\n",
       " 0.004503230098634958,\n",
       " 0.043096333742141724,\n",
       " -0.01868630200624466,\n",
       " -0.024979816749691963,\n",
       " 0.030431605875492096,\n",
       " 0.03631073236465454,\n",
       " -0.02021435648202896,\n",
       " 0.011389190331101418,\n",
       " 0.003726253053173423,\n",
       " 0.015397097915410995,\n",
       " -0.01357120182365179,\n",
       " -0.021444570273160934,\n",
       " -0.011829477734863758,\n",
       " -0.004179489798843861,\n",
       " -0.007705023977905512,\n",
       " 0.015215802937746048,\n",
       " 0.0060571846552193165,\n",
       " -0.0007490545976907015,\n",
       " 0.0028343480080366135,\n",
       " -0.008818691596388817,\n",
       " 0.0017158245900645852,\n",
       " 7.860823825467378e-05,\n",
       " 0.012723001651465893,\n",
       " 0.0005932544590905309,\n",
       " -0.039340946823358536,\n",
       " -0.036595627665519714,\n",
       " -0.03268484026193619,\n",
       " 0.05324883759021759,\n",
       " 0.002222478622570634,\n",
       " 0.000798829656559974,\n",
       " -0.0037748143076896667,\n",
       " -0.01925608515739441,\n",
       " 0.02542010322213173,\n",
       " 0.027582690119743347,\n",
       " 0.0043769716285169125,\n",
       " -0.01994241401553154,\n",
       " 0.02402154542505741,\n",
       " 0.0010642969282343984,\n",
       " 0.021146729588508606,\n",
       " -0.0058046672493219376,\n",
       " 0.00044392916606739163,\n",
       " 0.0089417127892375,\n",
       " 0.006753226742148399,\n",
       " -0.010709336027503014,\n",
       " -0.041386984288692474,\n",
       " -0.03965173661708832,\n",
       " 0.04120568931102753,\n",
       " -0.0012981994077563286,\n",
       " -0.010469767265021801,\n",
       " -0.02017550729215145,\n",
       " 0.007808620575815439,\n",
       " -0.0021431620698422194,\n",
       " 0.0034963972866535187,\n",
       " 0.017520835623145103,\n",
       " -0.006432723719626665,\n",
       " -0.04560856148600578,\n",
       " 0.010974803008139133,\n",
       " 0.03185606375336647,\n",
       " -0.009181280620396137,\n",
       " 0.012386311776936054,\n",
       " -0.018789898604154587,\n",
       " -0.0016203211853280663,\n",
       " -0.028411466628313065,\n",
       " -0.003103052731603384,\n",
       " 0.011900700628757477,\n",
       " 0.01544889621436596,\n",
       " 0.015086307190358639,\n",
       " 0.005911501590162516,\n",
       " 0.02416399121284485,\n",
       " -0.0017433426110073924,\n",
       " 0.026041686534881592,\n",
       " -0.03947044163942337,\n",
       " -0.011913650669157505,\n",
       " -0.021794211119413376,\n",
       " -0.002136687282472849,\n",
       " 0.018738100305199623,\n",
       " 0.023736653849482536,\n",
       " -0.027375496923923492,\n",
       " 0.015241703018546104,\n",
       " -0.03071649931371212,\n",
       " -0.015189903788268566,\n",
       " -0.034161098301410675,\n",
       " 0.027530891820788383,\n",
       " 0.0077891964465379715,\n",
       " 0.017559684813022614,\n",
       " -0.04156827926635742,\n",
       " 0.006325889378786087,\n",
       " 0.01750788651406765,\n",
       " 0.0067079029977321625,\n",
       " 0.0007409610552713275,\n",
       " -0.02488916926085949,\n",
       " -0.006720852572470903,\n",
       " -0.016161125153303146,\n",
       " -0.006351788528263569,\n",
       " 0.011538111604750156,\n",
       " 0.01031437236815691,\n",
       " -0.009252503514289856,\n",
       " -0.015928031876683235,\n",
       " 0.009466172195971012,\n",
       " -0.008015815168619156,\n",
       " -0.011292068287730217,\n",
       " -0.03201146051287651,\n",
       " -0.02280428074300289,\n",
       " -0.010087753646075726,\n",
       " 0.01689925417304039,\n",
       " 0.00733595946803689,\n",
       " -0.025135211646556854,\n",
       " -0.03390210494399071,\n",
       " -0.020343853160738945,\n",
       " -0.00011786177492467687,\n",
       " -0.026210030540823936,\n",
       " 0.02317981980741024,\n",
       " -0.02002011239528656,\n",
       " 0.0030447794124484062,\n",
       " -0.0091359568759799,\n",
       " 0.024189889430999756,\n",
       " 0.006102508399635553,\n",
       " 0.004276611842215061,\n",
       " 0.023529458791017532,\n",
       " -0.018867596983909607,\n",
       " -0.016951052471995354,\n",
       " -0.03322872519493103,\n",
       " -0.01507335714995861,\n",
       " 0.020641693845391273,\n",
       " -0.001222929684445262,\n",
       " 0.004726611077785492,\n",
       " 0.011266169138252735,\n",
       " -0.02523881010711193,\n",
       " -0.015630191192030907,\n",
       " -0.0002678952587302774,\n",
       " -0.013351058587431908,\n",
       " -0.02131507359445095,\n",
       " 0.019540976732969284,\n",
       " -0.0006826877943240106,\n",
       " 0.016161125153303146,\n",
       " 0.03680282086133957,\n",
       " -0.013804295100271702,\n",
       " 0.03884885832667351,\n",
       " -0.029136644676327705,\n",
       " -0.012043146416544914,\n",
       " 0.0159927811473608,\n",
       " -0.013247461058199406,\n",
       " -0.0157985370606184,\n",
       " -0.004917618352919817,\n",
       " -0.016873354092240334,\n",
       " -0.0025089888367801905,\n",
       " 0.0075302040204405785,\n",
       " 0.011615809053182602,\n",
       " 0.00037371795042417943,\n",
       " 0.02184600941836834,\n",
       " -0.0167438592761755,\n",
       " -0.0022160036023706198,\n",
       " 0.004658625926822424,\n",
       " 0.047576904296875,\n",
       " -0.02119852788746357,\n",
       " -0.01853090524673462,\n",
       " -0.025342406705021858,\n",
       " 0.011576959863305092,\n",
       " -0.027608590200543404,\n",
       " 0.01792227476835251,\n",
       " -0.009362575598061085,\n",
       " 0.017028750851750374,\n",
       " 0.010547465644776821,\n",
       " 0.014166884124279022,\n",
       " -0.004273374564945698,\n",
       " 0.019476227462291718,\n",
       " 0.0024264350067824125,\n",
       " -0.02086183801293373,\n",
       " 0.004632726311683655,\n",
       " -0.016536664217710495,\n",
       " 0.008779842406511307,\n",
       " -0.008307181298732758,\n",
       " 0.015966881066560745,\n",
       " -0.031027289107441902,\n",
       " -0.01303379237651825,\n",
       " -0.016381269320845604,\n",
       " -0.01531940046697855,\n",
       " 0.014892063103616238,\n",
       " -0.016303570941090584,\n",
       " 0.02683161199092865,\n",
       " -0.012470483779907227,\n",
       " -0.008112937211990356,\n",
       " 0.015202853828668594,\n",
       " -0.0079899150878191,\n",
       " 0.011525161564350128,\n",
       " -0.005704307463020086,\n",
       " -0.015125156380236149,\n",
       " 0.015578392893075943,\n",
       " -0.016070477664470673,\n",
       " 0.02659851871430874,\n",
       " -0.010612213052809238,\n",
       " -0.027738085016608238,\n",
       " -0.002342262538149953,\n",
       " 0.03509347140789032,\n",
       " 0.023037374019622803,\n",
       " 0.02633952721953392,\n",
       " 0.007264736574143171,\n",
       " 0.020266154780983925,\n",
       " 0.011738830246031284,\n",
       " -0.01758558303117752,\n",
       " 0.012509332969784737,\n",
       " -0.007355384062975645,\n",
       " -0.026805713772773743,\n",
       " 0.010249624028801918,\n",
       " -0.008818691596388817,\n",
       " -0.0012342606205493212,\n",
       " 0.020071910694241524,\n",
       " 0.02100428380072117,\n",
       " 0.023853199556469917,\n",
       " 0.017870474606752396,\n",
       " -0.004409345798194408,\n",
       " 0.003302152967080474,\n",
       " -0.008358979597687721,\n",
       " 0.01849205791950226,\n",
       " -0.019061841070652008,\n",
       " -0.0065751695074141026,\n",
       " 0.0038169005420058966,\n",
       " -0.01803882047533989,\n",
       " 0.01357120182365179,\n",
       " -0.00012979970779269934,\n",
       " 0.03612944111227989,\n",
       " 0.023166870698332787,\n",
       " -0.011479837819933891,\n",
       " 0.00688919797539711,\n",
       " -0.012671203352510929,\n",
       " -0.011823003180325031,\n",
       " -0.0040532308630645275,\n",
       " -0.019359681755304337,\n",
       " -0.0017595295794308186,\n",
       " -0.00863739661872387,\n",
       " 0.006594594102352858,\n",
       " -0.011046025902032852,\n",
       " -0.001000358141027391,\n",
       " -0.006079846527427435,\n",
       " 0.01276832539588213,\n",
       " 0.019968314096331596,\n",
       " 0.004150353372097015,\n",
       " 0.007931642234325409,\n",
       " 0.03794238716363907,\n",
       " -0.02025320567190647,\n",
       " 0.005367617588490248,\n",
       " 0.01078703347593546,\n",
       " -0.016316521912813187,\n",
       " -0.03040570765733719,\n",
       " 0.010528041049838066,\n",
       " 0.02207910269498825,\n",
       " 0.007627326063811779,\n",
       " -0.01986471749842167,\n",
       " 0.022661834955215454,\n",
       " -0.0053870417177677155,\n",
       " -0.023814350366592407,\n",
       " -0.017378389835357666,\n",
       " -0.00623200461268425,\n",
       " -0.0068503487855196,\n",
       " 9.287305874750018e-05,\n",
       " -0.018906444311141968,\n",
       " -0.0025170822627842426,\n",
       " 0.00201690336689353,\n",
       " 0.02196255512535572,\n",
       " 0.008967611938714981,\n",
       " 0.0020589896012097597,\n",
       " 0.02009781077504158,\n",
       " 0.028670458123087883,\n",
       " -0.004283086862415075,\n",
       " -0.00039172600372694433,\n",
       " -0.012625879608094692,\n",
       " 0.05293804779648781,\n",
       " 0.005730206612497568,\n",
       " -0.011842427775263786,\n",
       " 0.006186680868268013,\n",
       " -0.012956094928085804,\n",
       " -0.0075302040204405785,\n",
       " 0.014464725740253925,\n",
       " -0.0013014368014410138,\n",
       " -0.0029622255824506283,\n",
       " 0.006312939804047346,\n",
       " 0.01185537688434124,\n",
       " 0.0011598003329709172,\n",
       " -0.00020102261623833328,\n",
       " 0.01849205791950226,\n",
       " 0.030017219483852386,\n",
       " 0.025484852492809296,\n",
       " 0.02253233827650547,\n",
       " -0.02683161199092865,\n",
       " -0.012340988032519817,\n",
       " 0.04755100607872009,\n",
       " 0.09349625557661057,\n",
       " -0.012036671862006187,\n",
       " -0.02659851871430874,\n",
       " 0.01575968787074089,\n",
       " -0.013506453484296799,\n",
       " 0.0040856050327420235,\n",
       " -0.034420087933540344,\n",
       " -0.015164004638791084,\n",
       " 0.02481147088110447,\n",
       " -0.00022176223865244538,\n",
       " -0.0112273208796978,\n",
       " 0.02481147088110447,\n",
       " 0.028670458123087883,\n",
       " 0.011337392032146454,\n",
       " 0.010100703686475754,\n",
       " 0.014257531613111496,\n",
       " 0.0005386232514865696,\n",
       " 0.008015815168619156,\n",
       " -0.00826185755431652,\n",
       " 0.002203054027631879,\n",
       " 0.006895672529935837,\n",
       " -0.010301422327756882,\n",
       " 0.002403773134574294,\n",
       " 0.011512212455272675,\n",
       " 0.013415805995464325,\n",
       " 0.011466888710856438,\n",
       " 0.013325158506631851,\n",
       " 0.02527765743434429,\n",
       " -0.02371075376868248,\n",
       " -0.03167476877570152,\n",
       " -0.004542079288512468,\n",
       " 0.019502127543091774,\n",
       " -0.0167438592761755,\n",
       " 0.0034316491801291704,\n",
       " 0.00015640712808817625,\n",
       " 0.04128338769078255,\n",
       " -0.007705023977905512,\n",
       " 0.02192370593547821,\n",
       " -0.006338838953524828,\n",
       " -0.020499248057603836,\n",
       " -0.004713661503046751,\n",
       " -0.011466888710856438,\n",
       " 0.0137006975710392,\n",
       " -0.012878396548330784,\n",
       " -3.9759379433235154e-05,\n",
       " -0.017598534002900124,\n",
       " 0.032374050468206406,\n",
       " 0.027867581695318222,\n",
       " -0.0057107824832201,\n",
       " -0.0002660742320585996,\n",
       " 0.0017044937703758478,\n",
       " 0.013079116120934486,\n",
       " -0.053041644394397736,\n",
       " -0.02675391547381878,\n",
       " 0.00605071010068059,\n",
       " 0.021263275295495987,\n",
       " 0.009181280620396137,\n",
       " -0.0030221175402402878,\n",
       " -0.019269034266471863,\n",
       " -0.03431649133563042,\n",
       " -0.027038807049393654,\n",
       " 0.012690627947449684,\n",
       " 0.003642080584540963,\n",
       " -0.01784457638859749,\n",
       " 0.0043769716285169125,\n",
       " -0.02659851871430874,\n",
       " -0.012515807524323463,\n",
       " -0.00947912223637104,\n",
       " -0.02918844297528267,\n",
       " 0.009822286665439606,\n",
       " -0.007400707807391882,\n",
       " -0.01394674088805914,\n",
       " -0.013364007696509361,\n",
       " -0.009964732453227043,\n",
       " 0.011920125223696232,\n",
       " 0.010392069816589355,\n",
       " -0.0025122263468801975,\n",
       " -0.0015588104724884033,\n",
       " -0.029110746458172798,\n",
       " 0.019994212314486504,\n",
       " 0.0013799439184367657,\n",
       " -0.011784153990447521,\n",
       " -0.033591315150260925,\n",
       " -0.02885175310075283,\n",
       " -0.017896374687552452,\n",
       " -0.010152501985430717,\n",
       " -0.028074776753783226,\n",
       " -0.0011088112369179726,\n",
       " 0.003697116393595934,\n",
       " -0.011130197905004025,\n",
       " -0.009446747601032257,\n",
       " -0.01158990990370512,\n",
       " 0.02386614866554737,\n",
       " 0.011162572540342808,\n",
       " 0.021703563630580902,\n",
       " 0.03566325455904007,\n",
       " 0.013208611868321896,\n",
       " -0.0048755318857729435,\n",
       " 0.014892063103616238,\n",
       " -0.04475388675928116,\n",
       " 0.005668696016073227,\n",
       " -0.04206036403775215,\n",
       " -0.010812932625412941,\n",
       " -0.011259694583714008,\n",
       " 0.018207166343927383,\n",
       " 0.0014058430679142475,\n",
       " -0.02778988517820835,\n",
       " 0.0010837212903425097,\n",
       " 0.02428053691983223,\n",
       " -0.030845994129776955,\n",
       " 0.031881965696811676,\n",
       " -0.008812216110527515,\n",
       " 0.024940967559814453,\n",
       " 0.007174089550971985,\n",
       " 0.0009712214814499021,\n",
       " 0.0014843501849099994,\n",
       " 0.012697102501988411,\n",
       " 0.03356541320681572,\n",
       " 0.02180716022849083,\n",
       " -0.01171940565109253,\n",
       " 0.026365425437688828,\n",
       " -0.02078413963317871,\n",
       " -0.0027356070932000875,\n",
       " 0.009582718834280968,\n",
       " -0.009634517133235931,\n",
       " 0.0016721197171136737,\n",
       " 0.00287319696508348,\n",
       " -0.0034963972866535187,\n",
       " -0.026365425437688828,\n",
       " -0.009336675517261028,\n",
       " 0.01495681144297123,\n",
       " 0.015656091272830963,\n",
       " -0.009692790918052197,\n",
       " -0.030768297612667084,\n",
       " -0.029861822724342346,\n",
       " 0.0038427996914833784,\n",
       " -0.016912203282117844,\n",
       " 0.02747909352183342,\n",
       " -0.0018987379735335708,\n",
       " -0.02005896158516407,\n",
       " -0.0009072827524505556,\n",
       " -0.013467604294419289,\n",
       " 0.013253935612738132,\n",
       " -0.014969760552048683,\n",
       " 0.049338050186634064,\n",
       " -0.02828196994960308,\n",
       " -0.009220129810273647,\n",
       " 0.00786041934043169,\n",
       " -0.005471214186400175,\n",
       " 0.01731364242732525,\n",
       " -0.012755375355482101,\n",
       " 0.029810024425387383,\n",
       " -0.012949620373547077,\n",
       " -0.028437364846467972,\n",
       " -0.0009445128962397575,\n",
       " -0.008255382999777794,\n",
       " -0.00372949056327343,\n",
       " 0.008184160105884075,\n",
       " 0.037010014057159424,\n",
       " 0.039910729974508286,\n",
       " 0.00822300836443901,\n",
       " 0.006510421633720398,\n",
       " 0.020343853160738945,\n",
       " 0.011065450496971607,\n",
       " -0.026805713772773743,\n",
       " -0.00522193405777216,\n",
       " -0.010016530752182007,\n",
       " 0.003697116393595934,\n",
       " -0.013752496801316738,\n",
       " 0.027945280075073242,\n",
       " 0.007905743084847927,\n",
       " 0.001510249450802803,\n",
       " 0.006947471294552088,\n",
       " -0.00438668392598629,\n",
       " 0.02781578339636326,\n",
       " 0.02406039461493492,\n",
       " -0.0006826877943240106,\n",
       " -0.0224546417593956,\n",
       " -0.014166884124279022,\n",
       " 0.0012326419819146395,\n",
       " -0.013881992548704147,\n",
       " 0.03421289473772049,\n",
       " 0.007782721426337957,\n",
       " 0.02812657505273819,\n",
       " -0.030845994129776955,\n",
       " 0.024306437000632286,\n",
       " 0.024824421852827072,\n",
       " 0.005762580782175064,\n",
       " 0.0043445974588394165,\n",
       " -0.0023454998154193163,\n",
       " 0.01925608515739441,\n",
       " 0.020576946437358856,\n",
       " 0.006953945849090815,\n",
       " 0.005548912100493908,\n",
       " 0.0066075436770915985,\n",
       " -0.016238823533058167,\n",
       " -0.004781647119671106,\n",
       " -0.04125748947262764,\n",
       " 0.012094944715499878,\n",
       " 0.013415805995464325,\n",
       " 0.0016284147277474403,\n",
       " 0.011104298755526543,\n",
       " 0.01670501008629799,\n",
       " 0.010463292710483074,\n",
       " -0.0171323474496603,\n",
       " 0.004237763117998838,\n",
       " -0.024643126875162125,\n",
       " 0.007012219168245792,\n",
       " 0.0180776696652174,\n",
       " -0.017818676307797432,\n",
       " 0.010152501985430717,\n",
       " 0.00041681589209474623,\n",
       " -0.004869056865572929,\n",
       " -7.709070632699877e-05,\n",
       " 0.03584454953670502,\n",
       " 0.029628729447722435,\n",
       " 0.009887035004794598,\n",
       " 0.021949606016278267,\n",
       " -0.03175246715545654,\n",
       " -0.02592513896524906,\n",
       " -0.011997822672128677,\n",
       " -0.013007893227040768,\n",
       " 0.04193086922168732,\n",
       " -0.00012828217586502433,\n",
       " 0.044857483357191086,\n",
       " 0.01587623357772827,\n",
       " -0.01035322155803442,\n",
       " -0.02096543461084366,\n",
       " -0.023322265595197678,\n",
       " 0.007582002319395542,\n",
       " -0.005497113801538944,\n",
       " 0.00947912223637104,\n",
       " -0.010392069816589355,\n",
       " 0.001638126908801496,\n",
       " -0.015500695444643497,\n",
       " 0.016951052471995354,\n",
       " 0.010307897813618183,\n",
       " -0.0049629416316747665,\n",
       " -0.02724600024521351,\n",
       " 0.016912203282117844,\n",
       " -0.0035676201805472374,\n",
       " 0.02047334983944893,\n",
       " -0.001667263568378985,\n",
       " -0.014516524039208889,\n",
       " -0.009751063771545887,\n",
       " 0.04335532709956169,\n",
       " -0.006173731293529272,\n",
       " 0.015422997064888477,\n",
       " -0.007310060318559408,\n",
       " -0.015604292042553425,\n",
       " 0.012431635521352291,\n",
       " 0.024112192913889885,\n",
       " 0.004117979202419519,\n",
       " 0.02789348177611828,\n",
       " -0.01329925935715437,\n",
       " -0.0019116876646876335,\n",
       " 0.012632354162633419,\n",
       " 0.018945293501019478,\n",
       " -0.015332349576056004,\n",
       " -0.0008368691778741777,\n",
       " 0.012373361736536026,\n",
       " 0.0049629416316747665,\n",
       " -0.02455247938632965,\n",
       " 0.011505736969411373,\n",
       " 0.00984171126037836,\n",
       " 0.02485032007098198,\n",
       " 0.006134882569313049,\n",
       " 0.03252944350242615,\n",
       " 0.008242432959377766,\n",
       " 0.027012906968593597,\n",
       " -0.014387027360498905,\n",
       " 0.0016607887810096145,\n",
       " -0.005257545504719019,\n",
       " -0.00131762376986444,\n",
       " 0.022739533334970474,\n",
       " -0.010424444451928139,\n",
       " -0.013059691525995731,\n",
       " -0.0380718819797039,\n",
       " 0.005726969335228205,\n",
       " -0.010625163093209267,\n",
       " 0.019100690260529518,\n",
       " 0.017028750851750374,\n",
       " -0.023348163813352585,\n",
       " -0.006928046699613333,\n",
       " 0.02763448841869831,\n",
       " -0.015902133658528328,\n",
       " 0.009349625557661057,\n",
       " -0.016847455874085426,\n",
       " -0.002139924792572856,\n",
       " -0.02078413963317871,\n",
       " -0.04496107995510101,\n",
       " 0.0035546706058084965,\n",
       " -0.0027712187729775906,\n",
       " 0.017404289916157722,\n",
       " 0.0034769729245454073,\n",
       " 0.002353593474254012,\n",
       " -0.024332335218787193,\n",
       " 0.004593877587467432,\n",
       " -0.00395934609696269,\n",
       " -0.011732355691492558,\n",
       " -0.0038136630319058895,\n",
       " 0.004882006905972958,\n",
       " -0.044365398585796356,\n",
       " 0.015785586088895798,\n",
       " -0.020732341334223747,\n",
       " -0.011706456542015076,\n",
       " 0.025187009945511818,\n",
       " -0.0056136604398489,\n",
       " -0.0072582620196044445,\n",
       " 0.014943861402571201,\n",
       " 0.01796112209558487,\n",
       " 0.02657262049615383,\n",
       " -0.011143147945404053,\n",
       " -0.013467604294419289,\n",
       " -0.004943517502397299,\n",
       " 0.014166884124279022,\n",
       " -0.010320846922695637,\n",
       " 0.007692074403166771,\n",
       " -0.02797117829322815,\n",
       " -0.007471930701285601,\n",
       " -0.017326591536402702,\n",
       " 0.009258978068828583,\n",
       " 0.0009687934652902186,\n",
       " -0.010631637647747993,\n",
       " 0.00676617631688714,\n",
       " -0.029939521104097366,\n",
       " 0.0037392028607428074,\n",
       " -0.003001074306666851,\n",
       " -0.03224455192685127,\n",
       " -0.037398502230644226,\n",
       " -0.012386311776936054,\n",
       " 0.012140268459916115,\n",
       " 0.01548774540424347,\n",
       " 0.023387013003230095,\n",
       " 0.011156097985804081,\n",
       " 0.007368333637714386,\n",
       " -0.0019893853459507227,\n",
       " 0.001576616195961833,\n",
       " 0.005283445119857788,\n",
       " 0.01206257101148367,\n",
       " 0.0033442394342273474,\n",
       " -0.01978701911866665,\n",
       " 0.014387027360498905,\n",
       " 0.012781274504959583,\n",
       " -0.00035065141855739057,\n",
       " -0.014257531613111496,\n",
       " -0.021250326186418533,\n",
       " -0.005940638016909361,\n",
       " -0.03833087533712387,\n",
       " 0.001926255994476378,\n",
       " -0.028178373351693153,\n",
       " 0.0262618288397789,\n",
       " 0.022092051804065704,\n",
       " -0.02885175310075283,\n",
       " -0.015099257230758667,\n",
       " -0.021988455206155777,\n",
       " -0.017935223877429962,\n",
       " -0.01292372029274702,\n",
       " 0.0015871378127485514,\n",
       " 0.0029071897733956575,\n",
       " 0.004283086862415075,\n",
       " 0.03144167736172676,\n",
       " -0.0067273275926709175,\n",
       " 0.04897546395659447,\n",
       " -0.019437380135059357,\n",
       " 0.0026061111129820347,\n",
       " -0.015267602168023586,\n",
       " 0.015138105489313602,\n",
       " -0.005280207376927137,\n",
       " -0.01587623357772827,\n",
       " 0.02088773623108864,\n",
       " 0.004720136523246765,\n",
       " -0.019087739288806915,\n",
       " -0.01670501008629799,\n",
       " -0.0023762553464621305,\n",
       " -0.031648870557546616,\n",
       " 0.006740277167409658,\n",
       " 0.02576974406838417,\n",
       " -0.02641722373664379,\n",
       " -0.009006460197269917,\n",
       " 0.001177606056444347,\n",
       " 0.001539386110380292,\n",
       " 0.030172614380717278,\n",
       " 0.011428039520978928,\n",
       " 0.013441705144941807,\n",
       " -0.03763159364461899,\n",
       " 0.02885175310075283,\n",
       " -0.00243614730425179,\n",
       " -0.003454311052337289,\n",
       " -0.023115072399377823,\n",
       " 0.028437364846467972,\n",
       " -0.010333796963095665,\n",
       " -0.014205733314156532,\n",
       " -0.0005467167939059436,\n",
       " 0.0023017949424684048,\n",
       " -0.007536678574979305,\n",
       " -0.008702144958078861,\n",
       " -0.0011347103863954544,\n",
       " 0.01467191893607378,\n",
       " 0.005017977673560381,\n",
       " 0.020835937932133675,\n",
       " 0.02716830186545849,\n",
       " 0.012833073735237122,\n",
       " -0.02892945148050785,\n",
       " -0.02017550729215145,\n",
       " -0.0020962196867913008,\n",
       " -0.009284877218306065,\n",
       " -0.010961852967739105,\n",
       " 0.014801415614783764,\n",
       " -0.0338762067258358,\n",
       " 0.0157985370606184,\n",
       " -0.010994227603077888,\n",
       " 0.0027194202411919832,\n",
       " 0.013713647611439228,\n",
       " -0.004610064905136824,\n",
       " -0.0059244511649012566,\n",
       " 0.011680557392537594,\n",
       " -0.022674784064292908,\n",
       " -0.005361142568290234,\n",
       " 0.004671575501561165,\n",
       " -0.006193155888468027,\n",
       " 0.002028234302997589,\n",
       " -0.005739918909966946,\n",
       " -0.002976793795824051,\n",
       " -0.0036323682870715857,\n",
       " -0.023076223209500313,\n",
       " 0.005076250992715359,\n",
       " -0.01743018813431263,\n",
       " -0.00605071010068059,\n",
       " 0.02991362288594246,\n",
       " 0.001452785450965166,\n",
       " -0.021858958527445793,\n",
       " 0.0005276970332488418,\n",
       " -0.005914738867431879,\n",
       " -0.03325462341308594,\n",
       " 0.008967611938714981,\n",
       " 0.19134359061717987,\n",
       " -0.01917838677763939,\n",
       " -0.0033571890089660883,\n",
       " -0.003726253053173423,\n",
       " -0.0037683392874896526,\n",
       " 0.018815796822309494,\n",
       " 0.01640716753900051,\n",
       " 0.0031872252002358437,\n",
       " -0.006257903762161732,\n",
       " 0.004066180437803268,\n",
       " -0.0010359695879742503,\n",
       " 0.007491355296224356,\n",
       " -0.011764729395508766,\n",
       " -0.003561145393177867,\n",
       " 0.00887048989534378,\n",
       " -0.025225859135389328,\n",
       " -0.024539530277252197,\n",
       " -0.011699981987476349,\n",
       " -0.016355369240045547,\n",
       " 0.00883164070546627,\n",
       " 0.003700353903695941,\n",
       " 0.024953916668891907,\n",
       " -0.002288845367729664,\n",
       " -0.005247833672910929,\n",
       " 0.0491049587726593,\n",
       " -0.00013930958812125027,\n",
       " -0.0022127663251012564,\n",
       " 0.004409345798194408,\n",
       " 0.002321219304576516,\n",
       " 0.009084158577024937,\n",
       " -0.01838845945894718,\n",
       " -0.01815536618232727,\n",
       " 0.017650332301855087,\n",
       " 0.010683436878025532,\n",
       " -0.011674081906676292,\n",
       " -0.0014657351421192288,\n",
       " 0.018582705408334732,\n",
       " 0.00052081752801314,\n",
       " 0.031648870557546616,\n",
       " -0.009459697641432285,\n",
       " 0.032710738480091095,\n",
       " 0.010262574069201946,\n",
       " 0.027116503566503525,\n",
       " -0.018440259620547295,\n",
       " 0.01774097979068756,\n",
       " 0.009958257898688316,\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536, 1536)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector1), len(vector2), len(vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819651460848861"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999970210938"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating chroma vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_char_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chroma\n",
      "  Downloading Chroma-0.2.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: chroma\n",
      "  Building wheel for chroma (setup.py): started\n",
      "  Building wheel for chroma (setup.py): finished with status 'done'\n",
      "  Created wheel for chroma: filename=Chroma-0.2.0-py3-none-any.whl size=7115 sha256=5582f77efaff95ea1e467bafb18bd1280a8a75e21cf40f3d1296b685c0812b04\n",
      "  Stored in directory: c:\\users\\shett\\appdata\\local\\pip\\cache\\wheels\\1e\\fa\\86\\8424ec486f796a33032ac837f9d7830b182c286e88c3ad3554\n",
      "Successfully built chroma\n",
      "Installing collected packages: chroma\n",
      "Successfully installed chroma-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (2.9.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp39-cp39-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (4.67.0)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.68.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (8.5.0)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.1.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.28.3-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp39-cp39-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.24.0-cp39-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.1-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from importlib-resources->chromadb) (3.21.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
      "   ---------------------------------------- 0.0/617.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 617.9/617.9 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "Downloading grpcio-1.68.0-cp39-cp39-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.4 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.4/4.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.0.1-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 5.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.1 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.1 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.5/11.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.6/2.4 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httptools-0.6.4-cp39-cp39-win_amd64.whl (89 kB)\n",
      "Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading protobuf-5.28.3-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomli-2.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading watchfiles-0.24.0-cp39-none-win_amd64.whl (277 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-14.1-cp39-cp39-win_amd64.whl (163 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53834 sha256=a054dcbce0168c04bd4c77a2de77256cc9507633d1130dcd6d52f91f9eaf852d\n",
      "  Stored in directory: c:\\users\\shett\\appdata\\local\\pip\\cache\\wheels\\f7\\02\\64\\d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, wrapt, websockets, websocket-client, tomli, sympy, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, humanfriendly, huggingface-hub, googleapis-common-protos, deprecated, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.20 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.15 durationpy-0.9 fastapi-0.115.5 filelock-3.16.1 flatbuffers-24.3.25 fsspec-2024.10.0 google-auth-2.36.0 googleapis-common-protos-1.66.0 grpcio-1.68.0 httptools-0.6.4 huggingface-hub-0.26.2 humanfriendly-10.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.2 protobuf-5.28.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 starlette-0.41.3 sympy-1.13.3 tokenizers-0.20.3 tomli-2.1.0 typer-0.13.1 uvicorn-0.32.1 watchfiles-0.24.0 websocket-client-1.8.0 websockets-14.1 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=pages_char_split,embedding=embedding,persist_directory=\"./intro-ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shett\\AppData\\Local\\Temp\\ipykernel_21564\\2208344821.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_from_dir = Chroma(persist_directory=\"./intro-ds\",\n"
     ]
    }
   ],
   "source": [
    "vectorstore_from_dir = Chroma(persist_directory=\"./intro-ds\",\n",
    "                              embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What progrmming languages do data scientist uses?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = vectorstore.similarity_search(query=question, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations'), Document(metadata={}, page_content='All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool'), Document(metadata={}, page_content='Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning'), Document(metadata={}, page_content='Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable'), Document(metadata={}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on')]\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lecture Title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m retrieved_docs:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage Content:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLecture Title:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLecture Title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Lecture Title'"
     ]
    }
   ],
   "source": [
    "for i in retrieved_docs:\n",
    "    print(f\"Page Content:{i.page_content}\\n--------\\nLecture Title:{i.metadata['Lecture Title']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMR = Maximal Marginal Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = vectorstore.max_marginal_relevance_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    lambda_mult=0.7,\n",
    "    filter={\"Lecture Title\":\"Programming Languages and software employed in Data science \"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriever using vectorstore-backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type = 'mmr',\n",
    "                                     search_kwargs = {'k':3, \"lambda_mult\":0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002010BD296D0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.7})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what software do data scientist use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations'),\n",
       " Document(metadata={}, page_content='Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable'),\n",
       " Document(metadata={}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation : Stuffing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=\"./intro-ds\", embedding_function=OpenAIEmbeddings(model='text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type = 'mmr',\n",
    "                                     search_kwargs = {'k':3 , 'lambda_mult': 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "Answer the foll questions:\n",
    "{question}\n",
    "\n",
    "To answer the question , use only the following context:\n",
    "{context}\n",
    "\n",
    "At the end of response, specify the name of the lecture this context is taken from in the format:\n",
    "Resources: *Lecture Title*\n",
    "where *Lecture Title* should be substituted with the title of all resources lectures.\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shett\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3490: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model= 'gpt-4',\n",
    "    model_kwargs= {'seed':365},\n",
    "    max_tokens= 250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What software do data scientists use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({'context':retriever,\n",
    "         'question': RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations'),\n",
       "  Document(metadata={}, page_content='Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable'),\n",
       "  Document(metadata={}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application')],\n",
       " 'question': 'What software do data scientists use?'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({\n",
    "    'context': retriever,\n",
    "    'question': RunnablePassthrough()\n",
    "}\n",
    "         |prompt_template\n",
    "         |chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Data scientists use a combination of programming languages and software. R and Python are the most popular programming languages as they can manipulate data and are integrated within multiple data and data science software platforms. They are adaptable and suitable for mathematical and statistical computations. In terms of software, data scientists often use tools designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. Hadoop, in particular, is a critical software for big data, as it is a collection of programs.\\n\\nResources: Programming Languages & Software Employed in Data Science - All the Tools You Need', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 345, 'total_tokens': 462, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c211272d-73b5-47c5-9861-5b65c927fd14-0', usage_metadata={'input_tokens': 345, 'output_tokens': 117, 'total_tokens': 462, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({\n",
    "    'context': retriever,\n",
    "    'question': RunnablePassthrough()\n",
    "}\n",
    "         |prompt_template\n",
    "         |chat\n",
    "         |StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data scientists use a combination of programming languages and software. R and Python are the most popular tools used as they can manipulate data and are integrated within multiple data and data science software platforms. They are adaptable and suitable for mathematical and statistical computations. There is also an increasing use of software designed for working with big data, such as Apache Hadoop, Apache Hbase, and Mongo DB.\\n\\nResources: Not specified in the context.'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
